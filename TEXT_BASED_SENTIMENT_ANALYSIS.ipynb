{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  ASSIGNMENT 1 : Text BASED SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "PdDLp2nGuWbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Loading text\n"
      ],
      "metadata": {
        "id": "FldD4NVmvnqn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQqxT07zWCnO",
        "outputId": "6651ec08-8136-4786-b0bc-6ee03b09605f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/reviews\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/reviews/\n",
        "\n",
        "# Data Loading & Preprocessing\n",
        "file_path = 'Cell_Phones_and_Accessories_5.json'\n",
        "reviews_list = []\n",
        "\n",
        "# Load JSON file\n",
        "with open(file_path, 'r') as json_file:\n",
        "    for review_line in json_file:\n",
        "        data = json.loads(review_line)\n",
        "        reviews_list.append(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA PREPROCESSING\n",
        "\n",
        "\n",
        "\n",
        "*   Removal of punctuation\n",
        "*   Removal of stopwords\n",
        "*   Removal of unecessary columns\n",
        "*   Removal of stopwords\n",
        "\n"
      ],
      "metadata": {
        "id": "3ubJmbLavk1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain necessary columns\n",
        "keys_to_keep = ['reviewerID', 'asin', 'reviewText', 'overall', 'summary', 'reviewTime']\n",
        "filtered_reviews = [{key: review[key] for key in keys_to_keep if key in review} for review in reviews_list]\n",
        "\n",
        "# Convert text data to lowercase\n",
        "text_columns = ['reviewText', 'summary']\n",
        "for review in filtered_reviews:\n",
        "    for col in text_columns:\n",
        "        review[col] = review[col].lower()\n",
        "\n",
        "# Load stopwords\n",
        "%cd /content/drive/MyDrive/stopword_folder/\n",
        "stopwords_file = 'NLTK\\'s list of english stopwords'\n",
        "with open(stopwords_file, 'r') as file:\n",
        "    stopwords = set(file.read().splitlines())\n",
        "\n",
        "# Remove stopwords and punctuation\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation\n",
        "    return ' '.join([word for word in text.split() if word not in stopwords])\n",
        "\n",
        "for review in filtered_reviews:\n",
        "    for col in text_columns:\n",
        "        review[col] = clean_text(review[col])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNPNF9HwceIS",
        "outputId": "41583595-1974-4595-f7a8-638d206e7fe3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stopword_folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THEMATIC ANALYSIS\n"
      ],
      "metadata": {
        "id": "6meltvuu1N20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "#Calculating frequency for each word in positive and negative reiews:\n",
        " # Setting the threshold if overall rating is greater than 4.0 ,it will be considered as good review and less that 2.0 will be considered as negative review\n",
        " # we have used counter function to count the number of positive and negative reviews to get the count of words in each review text\n",
        "positive_reviews = []\n",
        "negative_reviews = []\n",
        "\n",
        "for review in filtered_reviews:\n",
        "    if review['overall'] >= 4.0:\n",
        "        positive_reviews.append(review)\n",
        "    elif review['overall'] <= 2.0:\n",
        "        negative_reviews.append(review)\n",
        "\n",
        "def word_frequency(reviews):\n",
        "    counter = Counter()\n",
        "    for review in reviews:\n",
        "        counter.update(review['reviewText'].split())\n",
        "    return counter\n",
        "\n",
        "positive_word_count = word_frequency(positive_reviews)\n",
        "negative_word_count = word_frequency(negative_reviews)\n",
        "\n",
        "def identify_keywords(word_count, threshold=4):\n",
        "    return {word: count for word, count in word_count.items() if count >= threshold}\n",
        "\n",
        "positive_keywords = identify_keywords(positive_word_count)\n",
        "negative_keywords = identify_keywords(negative_word_count)\n",
        "\n"
      ],
      "metadata": {
        "id": "19SFx5sP6aL7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEMANTIC ANALYSIS"
      ],
      "metadata": {
        "id": "fmYGa_mvHBi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_weights = {\"good\": 0.65, \"amazing\": 0.7, \"bad\": -0.5, \"worst\": -0.7, \"excellent\": 0.8, \"terrible\": -0.8}\n",
        "\n",
        "def sentiment_analysis(text, weights):\n",
        "    words = text.split()\n",
        "    score = sum(weights.get(word, 0) for word in words)\n",
        "    return score\n",
        "\n",
        "def categorize_sentiment(score, threshold=0.5):\n",
        "    if score > threshold:\n",
        "        return \"Positive\"\n",
        "    elif score < -threshold:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "%cd /content/drive/MyDrive/\n",
        "\n",
        "with open(\"sentiments.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "    for review in filtered_reviews:\n",
        "        review_text = review['reviewText']\n",
        "        score = sentiment_analysis(review_text, word_weights)\n",
        "        sentiment = categorize_sentiment(score)\n",
        "        file.write(f\"Review ID: {review['reviewerID']}, Sentiment: {sentiment}\\n\")\n",
        "        file.write(f\"Review Text: {review_text}\\n\")\n",
        "        file.write(\"*\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "EZKob7Gbe6s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5139f7-629a-480b-8c75-01a60453cd9f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    }
  ]
}